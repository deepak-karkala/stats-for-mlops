---
title: The CUPED Control Tower
description: Variance reduction and sequential testing for faster experimentation
---

<Aside tone="story">
After countless experiments, DriftCity's engineers built a control tower above the clouds — a system to measure experiments faster and more precisely without waiting weeks for data. CUPED and sequential testing became their secret weapons for accelerating learning.
</Aside>

<Callout title="What you'll learn">
  - How CUPED reduces variance in A/B tests using pre-experiment data
  - How sequential testing lets you peek early without inflating false-positive risk
  - How to implement both techniques with simple code and visual checks
  - When to combine these methods for maximum efficiency
</Callout>

## Why Variance Reduction Matters

High metric noise leads to slow experiments. A subtle 2% improvement in revenue can be drowned out by day-to-day randomness. The solution? **CUPED** (Controlled-experiment Using Pre-Experiment Data) uses correlated pre-period metrics to reduce post-period variance.

If baseline and experiment periods are correlated, we can subtract the predictable component:

**CUPED formula:**
```
Y_cuped = Y - θ(X - X̄)
```

Where:
- `Y` = observed experiment metric
- `X` = pre-experiment baseline metric
- `θ = Cov(X,Y) / Var(X)` = adjustment coefficient
- `X̄` = mean of baseline

The more correlated X and Y are, the greater the variance reduction.

## Interactive CUPED Demo

Adjust the correlation slider below to see how CUPED variance reduction works. Higher correlation between baseline and experiment metrics leads to greater variance reduction.

<CUPEDDemo dataUrl="/chapters/chapter-5/fixtures/cuped_demo.csv" />

**Observations:**
- Low correlation (ρ ≈ 0.2): minimal improvement
- High correlation (ρ ≈ 0.8): 64% variance reduction
- Variance reduction ≈ ρ² (correlation squared)

## Sequential Testing

Instead of fixing a sample size upfront, sequential testing analyzes cumulative data over time while controlling error rates. This allows early stopping when evidence is overwhelming.

<SequentialChart dataUrl="/chapters/chapter-5/fixtures/sequential_sim.csv" />

**Key points:**
- Orange line tracks p-value as samples accumulate
- Dashed lines represent significance thresholds (α = 0.05 and α = 0.01)
- When p-value crosses threshold, you can stop early with controlled Type I error
- Sequential testing typically saves 30-40% of samples compared to fixed-horizon tests

## Implementation Code

Here's how to generate CUPED demo data and implement the variance reduction:

<CodeTabs
  tabs={[
    {
      label: "Python: CUPED implementation",
      language: "python",
      code: `import numpy as np
import pandas as pd

# Load experiment data
df = pd.read_csv("cuped_demo.csv")

# Calculate adjustment coefficient θ
theta = np.cov(df["pre_metric"], df["post_metric"])[0,1] / np.var(df["pre_metric"])

# Apply CUPED adjustment
df["y_cuped"] = df["post_metric"] - theta * (df["pre_metric"] - df["pre_metric"].mean())

# Calculate variance reduction
reduction = 1 - df["y_cuped"].var() / df["post_metric"].var()
print(f"Variance reduction: {reduction:.2%}")`
    },
    {
      label: "Python: Sequential test simulation",
      language: "python",
      code: `import numpy as np
import pandas as pd
from scipy.stats import ttest_ind

rng = np.random.default_rng(14)
n_steps = 20
N_total = 10000
effect = 0.2  # Cohen's d

# Generate data
A = rng.normal(0, 1, N_total)  # Control
B = rng.normal(effect, 1, N_total)  # Treatment

# Sequential testing
records = []
for i in range(1, n_steps + 1):
    n = int(i * N_total / n_steps)
    t, p = ttest_ind(A[:n], B[:n])
    records.append({"n": n, "p_value": p})

df = pd.DataFrame(records)
print(df)`
    }
  ]}
/>

## Interpreting Results

<table>
  <thead>
    <tr>
      <th>Technique</th>
      <th>Goal</th>
      <th>Interpretation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>CUPED</td>
      <td>Reduce variance using pre-period covariate</td>
      <td>Narrower CI → faster detection</td>
    </tr>
    <tr>
      <td>Sequential</td>
      <td>Check significance progressively</td>
      <td>Detect early winners without bias</td>
    </tr>
    <tr>
      <td>Combined</td>
      <td>CUPED + Sequential</td>
      <td>Maximum sensitivity at minimal data cost</td>
    </tr>
  </tbody>
</table>

## Real-World Applications

<table>
  <thead>
    <tr>
      <th>Company</th>
      <th>Technique</th>
      <th>Outcome</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Airbnb</strong></td>
      <td>CUPED on booking conversion + pre-trip features</td>
      <td>Reduced required sample size by ≈40%</td>
    </tr>
    <tr>
      <td><strong>Netflix</strong></td>
      <td>Sequential testing (O'Brien-Fleming boundaries)</td>
      <td>Ends 10% of experiments early with controlled α</td>
    </tr>
    <tr>
      <td><strong>Uber</strong></td>
      <td>CUPED + guardrails</td>
      <td>Keeps experimentation latency low for re-ranking models</td>
    </tr>
  </tbody>
</table>

## Key Takeaways

<Callout tone="success" title="Precision Experimentation Checklist">
  - CUPED leverages pre-period metrics to reduce noise
  - Variance reduction ≈ faster decisions, smaller samples
  - Sequential testing controls Type I error while allowing early stopping
  - Combined methods enable continuous experimentation in production MLOps systems
</Callout>

<Aside tone="next">
Next → **Chapter 6: The City Restored** — bringing it all together with continuous monitoring and guardrail automation.
</Aside>
